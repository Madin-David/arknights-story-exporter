from __future__ import annotations

import json
import os
from urllib.parse import urlencode, quote
from bs4 import BeautifulSoup
from common import Requester, Story

class PRTSClient:
    HOME = "https://prts.wiki/"
    API = "https://prts.wiki/api.php"

    CACHE_FILE = "prts_cache.json"

    BASE_HEADERS = {
        "User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64)",
        "Referer": "https://prts.wiki/",
        "Accept": "text/html,application/xhtml+xml",
    }

    def __init__(self, use_cache=True, requester=None):
        self.requester = requester or Requester()
        self.session = self.requester.session
        self.initialized = False
        self.use_cache = use_cache

        self.memory_cache = None     # å…¨é‡å¯†å½•ç¼“å­˜
        self.cookie_cache = None     # Cookie ç¼“å­˜

        if use_cache:
            self._load_cache()

    # ------------------------------------------------------
    # ç¼“å­˜ç³»ç»Ÿ
    # ------------------------------------------------------
    def _load_cache(self):
        """åŠ è½½æœ¬åœ°ç¼“å­˜"""
        if not os.path.exists(self.CACHE_FILE):
            return

        try:
            with open(self.CACHE_FILE, "r", encoding="utf-8") as f:
                data = json.load(f)

            # Cookie
            if "cookies" in data:
                for k, v in data["cookies"].items():
                    self.session.cookies.set(k, v)
                print("âœ” å·²åŠ è½½ç¼“å­˜ Cookie")
                self.initialized = True

            # å¯†å½•æ•°æ®
            if "char_memory" in data:
                self.memory_cache = data["char_memory"]
                print(f"âœ” å·²åŠ è½½ç¼“å­˜å¯†å½•è®°å½•ï¼š{len(self.memory_cache)} æ¡")

        except Exception as e:
            print("âš  æ— æ³•è¯»å–ç¼“å­˜:", e)

    def _save_cache(self):
        """ä¿å­˜ç¼“å­˜æ–‡ä»¶"""
        data = {}

        # ä¿å­˜ Cookie
        data["cookies"] = {k: v for k, v in self.session.cookies.items()}

        # ä¿å­˜å¯†å½•
        if self.memory_cache is not None:
            data["char_memory"] = self.memory_cache

        with open(self.CACHE_FILE, "w", encoding="utf-8") as f:
            json.dump(data, f, ensure_ascii=False, indent=2)

        print("ğŸ’¾ ç¼“å­˜å·²ä¿å­˜ã€‚")

    # ------------------------------------------------------
    # åˆå§‹åŒ– Cookie
    # ------------------------------------------------------
    def init(self):
        """è‹¥å·²æœ‰ç¼“å­˜ Cookieåˆ™ç›´æ¥ä½¿ç”¨ï¼Œå¦åˆ™è®¿é—®é¦–é¡µè·å–æ–°çš„ Cookie"""
        if self.initialized:
            return

        print("ğŸŒ åˆå§‹åŒ–ï¼šæ­£åœ¨è·å– PRTS Cookie ...")

        r = self.requester.get(self.HOME, headers=self.BASE_HEADERS)
        r.raise_for_status()

        print("âœ” Cookie åˆå§‹åŒ–æˆåŠŸï¼š")
        for k, v in self.session.cookies.items():
            print("  ", k, "=", v)

        self.initialized = True
        self._save_cache()

    def refresh(self):
        """å¼ºåˆ¶é‡æ–°è·å– Cookie"""
        print("ğŸ”„ åˆ·æ–° Cookie ...")
        self.session.cookies.clear()
        self.initialized = False
        self.init()

    # ------------------------------------------------------
    # Cargo Query
    # ------------------------------------------------------
    def cargoquery(self, tables, fields, where=None, limit=5000):
        self.init()  # è‡ªåŠ¨åˆå§‹åŒ– Cookie

        params = {
            "action": "cargoquery",
            "format": "json",
            "tables": tables,
            "fields": fields,
            "limit": str(limit),
        }

        if where:
            params["where"] = where

        url = self.API + "?" + urlencode(params, quote_via=quote)

        r = self.session.get(url, headers=self.BASE_HEADERS)
        r.raise_for_status()

        data = r.json()
        return data.get("cargoquery", []), data

    # ------------------------------------------------------
    # å…¨é‡å¯†å½•æ•°æ®ï¼ˆMemoryListåŒæ¬¾ï¼‰
    # ------------------------------------------------------
    def get_all_memory(self):
        """è¿”å›å…¨é‡å¯†å½•æ•°æ®ï¼Œä¼˜å…ˆä½¿ç”¨æœ¬åœ°ç¼“å­˜"""
        if self.memory_cache is not None:
            return self.memory_cache

        print("â¬‡ æ­£åœ¨ä»æœåŠ¡å™¨åŠ è½½å…¨é‡å¯†å½•æ•°æ® ...")

        fields = (
            "_pageName=page,elite,level,favor,"
            "storySetName,storyIntro,storyTxt,storyIndex,medal"
        )

        rows, raw = self.cargoquery(
            tables="char_memory",
            fields=fields,
            limit=5000
        )

        print(f"âœ” å·²è·å– {len(rows)} æ¡å¯†å½•è®°å½•")

        # ä¿å­˜ç¼“å­˜
        self.memory_cache = rows
        self._save_cache()

        return rows

    # ------------------------------------------------------
    # æœç´¢æŸå¹²å‘˜å¯†å½•ï¼ˆå®Œå…¨æœ¬åœ°ï¼Œä¸è¯·æ±‚æœåŠ¡å™¨ï¼‰
    # ------------------------------------------------------
    def search_memory(self, name):
        """åœ¨ç¼“å­˜ä¸­æœç´¢ page == å¹²å‘˜å çš„å¯†å½•"""
        rows = self.get_all_memory()  # ä¿è¯å·²ç»åŠ è½½ç¼“å­˜æˆ–ä»æœåŠ¡å™¨è·å¾—

        result = [r for r in rows if r["title"]["page"] == name]
        return result

    def get_story_content_by_name(self, name: str) -> list[Story]:
        """è·å–æŒ‡å®šå¹²å‘˜çš„æœªè§£æå¯†å½•æ–‡æœ¬å†…å®¹"""
        entries = self.search_memory(name)
        stories = []
        for entry in entries:
            url = f"{self.HOME}w/{entry['title']['storyTxt']}"
            try:
                html = self.session.get(url).text
                soup = BeautifulSoup(html, 'html.parser')
                content = soup.find("pre", id="datas_txt")
                if content is None:
                    raise ValueError(f"æ— æ³•æ‰¾åˆ°å¯†å½•å†…å®¹çš„é¢„æ ¼å¼åŒ–æ–‡æœ¬å—ï¼Œé¡µé¢ç»“æ„å¯èƒ½å·²æ›´æ”¹: {url}")
                content = content.get_text()
                story = Story(
                    name=entry['title']['storySetName'],
                    intro=entry['title']['storyIntro'],
                    origin_content=content
                )
                stories.append(story)
            except Exception as e:
                print(f"âš  è·å–å¯†å½• '{entry['title']['storySetName']}' æ—¶å‡ºé”™: {e}")
                continue

        return stories